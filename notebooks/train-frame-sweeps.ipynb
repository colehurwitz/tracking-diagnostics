{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep over `train_frames` and `losses_to_use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from lightning_pose.utils.io import return_absolute_data_paths\n",
    "from lightning_pose.utils.scripts import get_imgaug_transform, get_dataset, get_data_module, get_loss_factories\n",
    "from lightning_pose.losses.losses import PCALoss\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/tracking-diagnostics')\n",
    "from diagnostics.handler import ModelHandler\n",
    "from diagnostics.io import get_base_config, get_keypoint_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% get config\n",
    "dataset_name = \"rick-configs-1\"\n",
    "base_config_dir = \"/home/jovyan/rick-configs-1\"\n",
    "base_save_dir = \"/home/jovyan/\"\n",
    "cfg = get_base_config(config_dir=base_config_dir, config_name=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load ground truth labels\n",
    "csv_file = os.path.join(cfg.data.data_dir, cfg.data.csv_file)\n",
    "csv_data = pd.read_csv(csv_file, header=list(cfg.data.header_rows))\n",
    "keypoints_gt = csv_data.iloc[:, 1:].to_numpy().reshape(csv_data.shape[0], -1, 2)\n",
    "\n",
    "keypoint_names = get_keypoint_names(csv_data, cfg.data.header_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section loops over single `losses_to_use`. no combos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by looping over `train_frames` and individual `losses_to_use`. Later build in complication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Searching for train_frames: 100, loss_type: []...\n",
      "name_str: s*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/3\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['pca_multiview']...\n",
      "name_str: pca_m*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/18\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['pca_singleview']...\n",
      "name_str: pca_s*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/2\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['temporal']...\n",
      "name_str: tempo*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/8\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['unimodal_mse']...\n",
      "name_str: unimo*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/13\n",
      "==========================\n",
      "Found 5 models out of 5.\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"/home/jovyan/lightning-pose\"\n",
    "loss_types = [[], [\"pca_multiview\"], [\"pca_singleview\"], [\"temporal\"], [\"unimodal_mse\"]] # TODO: add [\"pca_singleview\"] TODO: order matters\n",
    "log_weight_list = [] # TODO: order matters\n",
    "model_names = [\"train_frames_sweep\"]*len(loss_types)\n",
    "supervised_model_name = model_names[0] # they all have the same name\n",
    "train_frames_list = [50,75,100,125]\n",
    "model_type = \"heatmap\"\n",
    "handlers = []\n",
    "name_strs_to_plot = []\n",
    "for tr_fr_idx, train_frames in enumerate(train_frames_list):\n",
    "    for loss_idx, loss in enumerate(loss_types):\n",
    "        print(\"==========================\")\n",
    "        print(\"Searching for train_frames: {}, loss_type: {}...\".format(train_frames, loss))\n",
    "        # TODO: multi-loss version below, if needed\n",
    "        # name_strs_to_plot = ['+'.join([l[:5] for l in loss]) if len(loss)>0 else 's' for loss in loss_types]\n",
    "        name_str = '*'.join([loss[0][:5] if len(loss)==1 else 's', str(train_frames)])\n",
    "        print(\"name_str: {}\".format(name_str)) # TODO: just for single losses now\n",
    "        name_strs_to_plot.append(name_str) \n",
    "        model_cfg = cfg.copy()\n",
    "        model_cfg.training.train_frames = train_frames\n",
    "        model_cfg.model.losses_to_use = loss # assume loss is already a list, [] if supervised\n",
    "        model_cfg.model.model_name = model_names[loss_idx]\n",
    "        model_cfg.model.model_type = model_type\n",
    "        # specific arguments to \"train_frames_sweep\" models. TODO: change if needed\n",
    "        model_cfg.training.train_prob=0.2\n",
    "        model_cfg.training.val_prob=0.2\n",
    "        model_cfg.training.min_epochs=125\n",
    "        model_cfg.training.max_epochs=2000\n",
    "        if len(loss) == 0:\n",
    "            # support for uniquely-named supervised models\n",
    "            model_cfg.model.model_name = supervised_model_name\n",
    "        else:\n",
    "            # loop over the sub losses\n",
    "            if len(log_weight_list)>0:\n",
    "                for sub_loss_idx,sub_loss in enumerate(loss):\n",
    "                    model_cfg.losses[sub_loss].log_weight = log_weight_list[loss_idx][sub_loss_idx]\n",
    "        \n",
    "        try:\n",
    "            handlers.append(ModelHandler(save_dir, model_cfg, verbose=False))\n",
    "            print(\"Found: {}\".format(model_cfg.model.model_name))\n",
    "            print(\"In: {}\".format(handlers[-1].model_dir))\n",
    "        except FileNotFoundError:\n",
    "            print('did not find %s model for train_frames=%i' % (loss, train_frames))\n",
    "            continue\n",
    "# report on the models found\n",
    "print(\"==========================\")\n",
    "print(\"Found {} models out of {}.\".format(len(handlers), len(train_frames_list)*len(loss_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over handlers and compute metrics\n",
    "to_compute = \"rmse\" # | \"rmse\" | \"pca_singleview\" | \"unimodal_mse\"\n",
    "keypoint_names = get_keypoint_names(csv_data, cfg.data.header_rows)\n",
    "error_metric = \"reprojection_error\" # only for PCA\n",
    "pca_loss = None\n",
    "data_module = None\n",
    "\n",
    "# store results here\n",
    "if to_compute == \"pca_singleview\":\n",
    "    # remove obstacle keypoints\n",
    "    keypoint_names = [kp for kp in keypoint_names if kp not in ['obs_top','obsHigh_bot','obsLow_bot']]\n",
    "    print(keypoint_names)\n",
    "\n",
    "metrics_collected = {bp: [] for bp in keypoint_names}\n",
    "# can change this as a function of train_frames\n",
    "    \n",
    "for hand_idx, handler in enumerate(handlers):\n",
    "    print(hand_idx)\n",
    "    print(\"name: {}\".format(handler.cfg.model.model_name))\n",
    "    print(\"losses_to_use: {}\".format(handler.cfg.model.losses_to_use))\n",
    "    print(handler.model_dir)\n",
    "    if to_compute == 'rmse':\n",
    "        y_label = 'RMSE per bodypart'\n",
    "    elif to_compute == 'pca_multiview' or to_compute == 'pca_singleview':\n",
    "        y_label = 'PCA reprojection error'\n",
    "        model_cfg.model.losses_to_use = [to_compute] # TODO: not sure that makes sense here. assume loss is already a list, [] f\n",
    "        model_cfg.training.train_frames = handler.cfg.training.train_frames\n",
    "        data_dir, video_dir = return_absolute_data_paths(data_cfg=handler.cfg.data)\n",
    "        imgaug_transform = get_imgaug_transform(cfg=handler.cfg)\n",
    "        dataset = get_dataset(cfg=handler.cfg, data_dir=data_dir, imgaug_transform=imgaug_transform)\n",
    "        data_module = get_data_module(cfg=handler.cfg, dataset=dataset, video_dir=video_dir)\n",
    "        data_module.setup()\n",
    "        # compute pca params\n",
    "        loss_factories = get_loss_factories(cfg=model_cfg, data_module=data_module) # TODO: keeping model_cfg here for now\n",
    "        pca_loss = loss_factories[\"unsupervised\"].loss_instance_dict[to_compute]\n",
    "    # compute metric\n",
    "    try:\n",
    "        result = handler.compute_metric(\n",
    "            to_compute, 'predictions.csv',\n",
    "            keypoints_true=keypoints_gt, pca_loss_obj=pca_loss, datamodule=data_module)\n",
    "        print(result.shape)\n",
    "    except FileNotFoundError:\n",
    "        print('could not find model predictions')\n",
    "        continue\n",
    "    for b, bodypart in enumerate(keypoint_names):\n",
    "        metrics_collected[bodypart].append(result[:, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name_strs_to_plot)\n",
    "for col_name, metric in zip(name_strs_to_plot, metrics_collected[bodypart]):\n",
    "    print(col_name)\n",
    "    print(metric.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect results\n",
    "# TODO: currently ignorant of the train_frames. either fix here or above.               \n",
    "results_df = []\n",
    "for bodypart in keypoint_names:\n",
    "    dict_tmp = {\n",
    "        'bodypart': bodypart,\n",
    "        #'rng_seed': rng_seed,\n",
    "        'eval_mode': handlers[-1].pred_df.iloc[:, -1].to_numpy(),\n",
    "        'img_file': csv_data.iloc[:, 0], # TODO: fix, this is wrong. should be a str not a float\n",
    "    }\n",
    "    for col_name, metric in zip(name_strs_to_plot, metrics_collected[bodypart]):\n",
    "        dict_tmp[col_name] = metric\n",
    "    results_df.append(pd.DataFrame(dict_tmp))\n",
    "\n",
    "results_df = pd.concat(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.melt(\n",
    "    results_df, \n",
    "    id_vars=['bodypart', 'img_file', 'eval_mode'], \n",
    "    value_vars=name_strs_to_plot,\n",
    ")\n",
    "def add_loss_name_col(row):\n",
    "    return '_'.join(row['variable'].split('_')[:-1])\n",
    "def add_loss_val_col(row):\n",
    "    return row['variable'].split('_')[-1]\n",
    "df_tmp['loss'] = df_tmp.apply(add_loss_name_col, axis=1) # TODO: not doing anything but fails otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"loss_type\"] = df_tmp.variable.str.split('*').str[0]\n",
    "df_tmp[\"train_frames\"] = df_tmp.variable.str.split('*').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have multiple columns\n",
    "sns.set(context='talk', style='whitegrid', font_scale=1, rc = {'figure.figsize':(20,40)})\n",
    "eval_mode = 'test'\n",
    "saving_format = 'eps'\n",
    "y_label = \"Singleview PCA reconstruction error (pix.)\"\n",
    "hue_order = ['s', 'unimo', 'tempo', 'pca_s', 'pca_m']\n",
    "num_losses_to_plot = 20 #len(cols_collected) # can exclude vals here\n",
    "# average over keypoints and frames\n",
    "df_tmp_ = df_tmp[df_tmp.eval_mode==eval_mode]\n",
    "g = sns.catplot(\n",
    "    data=df_tmp_, x='train_frames', hue=\"loss_type\", y='value', kind='bar', hue_order=hue_order\n",
    ")\n",
    "# for ax in g.axes:\n",
    "#     plt.setp(ax.get_yticklabels(), visible=True, rotation=None)\n",
    "#g.set_xticklabels(rotation=80, ha='center')\n",
    "# plt.title(\"train frames: {}, metric: {}, {} data\".format(train_frames, to_compute, eval_mode))\n",
    "plt.ylabel(\"{}\".format(y_label))\n",
    "plt.gcf().set_size_inches(12, 8)\n",
    "plt.savefig('/home/jovyan/figs/{}_{}_{}_losses.{}'.format(to_compute, eval_mode, y_label, saving_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This section loops over combos, no inividual losses\n",
    "Loop over train_frames. Loop over all combos for a giving number of train frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================\n",
      "Searching for train_frames: 50, loss_type: ['temporal', 'unimodal_mse']...\n",
      "name_str: tempo+unimo*50\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/21\n",
      "==========================\n",
      "Searching for train_frames: 50, loss_type: ['temporal', 'pca_multiview']...\n",
      "name_str: tempo+pca_m*50\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/26\n",
      "==========================\n",
      "Searching for train_frames: 50, loss_type: ['temporal', 'unimodal_mse', 'pca_multiview']...\n",
      "name_str: tempo+unimo+pca_m*50\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/31\n",
      "==========================\n",
      "Searching for train_frames: 50, loss_type: ['unimodal_mse', 'pca_multiview']...\n",
      "name_str: unimo+pca_m*50\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/36\n",
      "==========================\n",
      "Searching for train_frames: 50, loss_type: ['pca_singleview', 'unimodal_mse']...\n",
      "name_str: pca_s+unimo*50\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/4\n",
      "==========================\n",
      "Searching for train_frames: 50, loss_type: ['pca_singleview', 'temporal']...\n",
      "name_str: pca_s+tempo*50\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/8\n",
      "==========================\n",
      "Searching for train_frames: 50, loss_type: ['pca_singleview', 'pca_multiview']...\n",
      "name_str: pca_s+pca_m*50\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/12\n",
      "==========================\n",
      "Searching for train_frames: 50, loss_type: ['pca_singleview', 'unimodal_mse', 'temporal']...\n",
      "name_str: pca_s+unimo+tempo*50\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/16\n",
      "==========================\n",
      "Searching for train_frames: 50, loss_type: ['pca_singleview', 'unimodal_mse', 'pca_multiview']...\n",
      "name_str: pca_s+unimo+pca_m*50\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/20\n",
      "==========================\n",
      "Searching for train_frames: 50, loss_type: ['pca_singleview', 'unimodal_mse', 'pca_multiview', 'temporal']...\n",
      "name_str: pca_s+unimo+pca_m+tempo*50\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/24\n",
      "==========================\n",
      "Searching for train_frames: 75, loss_type: ['temporal', 'unimodal_mse']...\n",
      "name_str: tempo+unimo*75\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/22\n",
      "==========================\n",
      "Searching for train_frames: 75, loss_type: ['temporal', 'pca_multiview']...\n",
      "name_str: tempo+pca_m*75\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/27\n",
      "==========================\n",
      "Searching for train_frames: 75, loss_type: ['temporal', 'unimodal_mse', 'pca_multiview']...\n",
      "name_str: tempo+unimo+pca_m*75\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/32\n",
      "==========================\n",
      "Searching for train_frames: 75, loss_type: ['unimodal_mse', 'pca_multiview']...\n",
      "name_str: unimo+pca_m*75\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/37\n",
      "==========================\n",
      "Searching for train_frames: 75, loss_type: ['pca_singleview', 'unimodal_mse']...\n",
      "name_str: pca_s+unimo*75\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/5\n",
      "==========================\n",
      "Searching for train_frames: 75, loss_type: ['pca_singleview', 'temporal']...\n",
      "name_str: pca_s+tempo*75\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/9\n",
      "==========================\n",
      "Searching for train_frames: 75, loss_type: ['pca_singleview', 'pca_multiview']...\n",
      "name_str: pca_s+pca_m*75\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/13\n",
      "==========================\n",
      "Searching for train_frames: 75, loss_type: ['pca_singleview', 'unimodal_mse', 'temporal']...\n",
      "name_str: pca_s+unimo+tempo*75\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/17\n",
      "==========================\n",
      "Searching for train_frames: 75, loss_type: ['pca_singleview', 'unimodal_mse', 'pca_multiview']...\n",
      "name_str: pca_s+unimo+pca_m*75\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/21\n",
      "==========================\n",
      "Searching for train_frames: 75, loss_type: ['pca_singleview', 'unimodal_mse', 'pca_multiview', 'temporal']...\n",
      "name_str: pca_s+unimo+pca_m+tempo*75\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/25\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['temporal', 'unimodal_mse']...\n",
      "name_str: tempo+unimo*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/23\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['temporal', 'pca_multiview']...\n",
      "name_str: tempo+pca_m*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/28\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['temporal', 'unimodal_mse', 'pca_multiview']...\n",
      "name_str: tempo+unimo+pca_m*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/33\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['unimodal_mse', 'pca_multiview']...\n",
      "name_str: unimo+pca_m*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/38\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['pca_singleview', 'unimodal_mse']...\n",
      "name_str: pca_s+unimo*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/6\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['pca_singleview', 'temporal']...\n",
      "name_str: pca_s+tempo*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/10\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['pca_singleview', 'pca_multiview']...\n",
      "name_str: pca_s+pca_m*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/14\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['pca_singleview', 'unimodal_mse', 'temporal']...\n",
      "name_str: pca_s+unimo+tempo*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/18\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['pca_singleview', 'unimodal_mse', 'pca_multiview']...\n",
      "name_str: pca_s+unimo+pca_m*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/22\n",
      "==========================\n",
      "Searching for train_frames: 100, loss_type: ['pca_singleview', 'unimodal_mse', 'pca_multiview', 'temporal']...\n",
      "name_str: pca_s+unimo+pca_m+tempo*100\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/26\n",
      "==========================\n",
      "Searching for train_frames: 125, loss_type: ['temporal', 'unimodal_mse']...\n",
      "name_str: tempo+unimo*125\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/24\n",
      "==========================\n",
      "Searching for train_frames: 125, loss_type: ['temporal', 'pca_multiview']...\n",
      "name_str: tempo+pca_m*125\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/29\n",
      "==========================\n",
      "Searching for train_frames: 125, loss_type: ['temporal', 'unimodal_mse', 'pca_multiview']...\n",
      "name_str: tempo+unimo+pca_m*125\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/34\n",
      "==========================\n",
      "Searching for train_frames: 125, loss_type: ['unimodal_mse', 'pca_multiview']...\n",
      "name_str: unimo+pca_m*125\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/39\n",
      "==========================\n",
      "Searching for train_frames: 125, loss_type: ['pca_singleview', 'unimodal_mse']...\n",
      "name_str: pca_s+unimo*125\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/7\n",
      "==========================\n",
      "Searching for train_frames: 125, loss_type: ['pca_singleview', 'temporal']...\n",
      "name_str: pca_s+tempo*125\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/11\n",
      "==========================\n",
      "Searching for train_frames: 125, loss_type: ['pca_singleview', 'pca_multiview']...\n",
      "name_str: pca_s+pca_m*125\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/15\n",
      "==========================\n",
      "Searching for train_frames: 125, loss_type: ['pca_singleview', 'unimodal_mse', 'temporal']...\n",
      "name_str: pca_s+unimo+tempo*125\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/19\n",
      "==========================\n",
      "Searching for train_frames: 125, loss_type: ['pca_singleview', 'unimodal_mse', 'pca_multiview']...\n",
      "name_str: pca_s+unimo+pca_m*125\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/23\n",
      "==========================\n",
      "Searching for train_frames: 125, loss_type: ['pca_singleview', 'unimodal_mse', 'pca_multiview', 'temporal']...\n",
      "name_str: pca_s+unimo+pca_m+tempo*125\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/27\n",
      "==========================\n",
      "Found 40 models out of 40.\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"/home/jovyan/lightning-pose\"\n",
    "loss_types = [[\"temporal\",\"unimodal_mse\"],[\"temporal\",\"pca_multiview\"],[\"temporal\",\"unimodal_mse\",\"pca_multiview\"], \\\n",
    "    [\"unimodal_mse\",\"pca_multiview\"], [\"pca_singleview\",\"unimodal_mse\"],[\"pca_singleview\",\"temporal\"], \\\n",
    "        [\"pca_singleview\",\"pca_multiview\"],[\"pca_singleview\",\"unimodal_mse\",\"temporal\"],[\"pca_singleview\",\"unimodal_mse\",\"pca_multiview\"],[\"pca_singleview\",\"unimodal_mse\",\"pca_multiview\",\"temporal\"]] # TODO: add [\"pca_singleview\"] TODO: order matters\n",
    "log_weight_list = [] # TODO: order matters\n",
    "model_names = [\"train_frames_sweep\"]*len(loss_types)\n",
    "supervised_model_name = model_names[0] # they all have the same name\n",
    "train_frames_list = [50,75,100,125]\n",
    "model_type = \"heatmap\"\n",
    "handlers = []\n",
    "name_strs_to_plot = []\n",
    "for tr_fr_idx, train_frames in enumerate(train_frames_list):\n",
    "    for loss_idx, loss in enumerate(loss_types):\n",
    "        print(\"==========================\")\n",
    "        print(\"Searching for train_frames: {}, loss_type: {}...\".format(train_frames, loss))\n",
    "        # TODO: multi-loss version below, if needed\n",
    "        loss_str = '+'.join([l[:5] for l in loss] if len(loss)>0 else 's')\n",
    "        # name_strs_to_plot = ['+'.join([l[:5] for l in loss]) if len(loss)>0 else 's' for loss in loss_types]\n",
    "        name_str = '*'.join([loss_str, str(train_frames)])\n",
    "        print(\"name_str: {}\".format(name_str)) # TODO: just for single losses now\n",
    "        name_strs_to_plot.append(name_str) \n",
    "        model_cfg = cfg.copy()\n",
    "        model_cfg.training.train_frames = train_frames\n",
    "        model_cfg.model.losses_to_use = loss # assume loss is already a list, [] if supervised\n",
    "        model_cfg.model.model_name = model_names[loss_idx]\n",
    "        model_cfg.model.model_type = model_type\n",
    "        # specific arguments to \"train_frames_sweep\" models. TODO: change if needed\n",
    "        model_cfg.training.train_prob=0.2\n",
    "        model_cfg.training.val_prob=0.2\n",
    "        model_cfg.training.min_epochs=125\n",
    "        model_cfg.training.max_epochs=2000\n",
    "        if len(loss) == 0:\n",
    "            # support for uniquely-named supervised models\n",
    "            model_cfg.model.model_name = supervised_model_name\n",
    "        else:\n",
    "            # loop over the sub losses\n",
    "            if len(log_weight_list)>0:\n",
    "                for sub_loss_idx,sub_loss in enumerate(loss):\n",
    "                    model_cfg.losses[sub_loss].log_weight = log_weight_list[loss_idx][sub_loss_idx]\n",
    "        \n",
    "        try:\n",
    "            handlers.append(ModelHandler(save_dir, model_cfg, verbose=False))\n",
    "            print(\"Found: {}\".format(model_cfg.model.model_name))\n",
    "            print(\"In: {}\".format(handlers[-1].model_dir))\n",
    "        except FileNotFoundError:\n",
    "            print('did not find %s model for train_frames=%i' % (loss, train_frames))\n",
    "            continue\n",
    "# report on the models found\n",
    "print(\"==========================\")\n",
    "print(\"Found {} models out of {}.\".format(len(handlers), len(train_frames_list)*len(loss_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0\n",
      "name: train_frames_sweep\n",
      "train_frames: 50\n",
      "losses_to_use: ['temporal', 'unimodal_mse']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/21\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 1\n",
      "name: train_frames_sweep\n",
      "train_frames: 50\n",
      "losses_to_use: ['temporal', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/26\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 2\n",
      "name: train_frames_sweep\n",
      "train_frames: 50\n",
      "losses_to_use: ['temporal', 'unimodal_mse', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/31\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 3\n",
      "name: train_frames_sweep\n",
      "train_frames: 50\n",
      "losses_to_use: ['unimodal_mse', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/36\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 4\n",
      "name: train_frames_sweep\n",
      "train_frames: 50\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/4\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 5\n",
      "name: train_frames_sweep\n",
      "train_frames: 50\n",
      "losses_to_use: ['pca_singleview', 'temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/8\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 6\n",
      "name: train_frames_sweep\n",
      "train_frames: 50\n",
      "losses_to_use: ['pca_singleview', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/12\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 7\n",
      "name: train_frames_sweep\n",
      "train_frames: 50\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse', 'temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/16\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 8\n",
      "name: train_frames_sweep\n",
      "train_frames: 50\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/20\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 9\n",
      "name: train_frames_sweep\n",
      "train_frames: 50\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse', 'pca_multiview', 'temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/24\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 10\n",
      "name: train_frames_sweep\n",
      "train_frames: 75\n",
      "losses_to_use: ['temporal', 'unimodal_mse']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/22\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 11\n",
      "name: train_frames_sweep\n",
      "train_frames: 75\n",
      "losses_to_use: ['temporal', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/27\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 12\n",
      "name: train_frames_sweep\n",
      "train_frames: 75\n",
      "losses_to_use: ['temporal', 'unimodal_mse', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/32\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 13\n",
      "name: train_frames_sweep\n",
      "train_frames: 75\n",
      "losses_to_use: ['unimodal_mse', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/37\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 14\n",
      "name: train_frames_sweep\n",
      "train_frames: 75\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/5\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 15\n",
      "name: train_frames_sweep\n",
      "train_frames: 75\n",
      "losses_to_use: ['pca_singleview', 'temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/9\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 16\n",
      "name: train_frames_sweep\n",
      "train_frames: 75\n",
      "losses_to_use: ['pca_singleview', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/13\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 17\n",
      "name: train_frames_sweep\n",
      "train_frames: 75\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse', 'temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/17\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 18\n",
      "name: train_frames_sweep\n",
      "train_frames: 75\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/21\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 19\n",
      "name: train_frames_sweep\n",
      "train_frames: 75\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse', 'pca_multiview', 'temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/25\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 20\n",
      "name: train_frames_sweep\n",
      "train_frames: 100\n",
      "losses_to_use: ['temporal', 'unimodal_mse']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/23\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 21\n",
      "name: train_frames_sweep\n",
      "train_frames: 100\n",
      "losses_to_use: ['temporal', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/28\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 22\n",
      "name: train_frames_sweep\n",
      "train_frames: 100\n",
      "losses_to_use: ['temporal', 'unimodal_mse', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/33\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 23\n",
      "name: train_frames_sweep\n",
      "train_frames: 100\n",
      "losses_to_use: ['unimodal_mse', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/38\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 24\n",
      "name: train_frames_sweep\n",
      "train_frames: 100\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/6\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 25\n",
      "name: train_frames_sweep\n",
      "train_frames: 100\n",
      "losses_to_use: ['pca_singleview', 'temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/10\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 26\n",
      "name: train_frames_sweep\n",
      "train_frames: 100\n",
      "losses_to_use: ['pca_singleview', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/14\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 27\n",
      "name: train_frames_sweep\n",
      "train_frames: 100\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse', 'temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/18\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 28\n",
      "name: train_frames_sweep\n",
      "train_frames: 100\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/22\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 29\n",
      "name: train_frames_sweep\n",
      "train_frames: 100\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse', 'pca_multiview', 'temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/26\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 30\n",
      "name: train_frames_sweep\n",
      "train_frames: 125\n",
      "losses_to_use: ['temporal', 'unimodal_mse']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/24\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 31\n",
      "name: train_frames_sweep\n",
      "train_frames: 125\n",
      "losses_to_use: ['temporal', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/29\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 32\n",
      "name: train_frames_sweep\n",
      "train_frames: 125\n",
      "losses_to_use: ['temporal', 'unimodal_mse', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/34\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 33\n",
      "name: train_frames_sweep\n",
      "train_frames: 125\n",
      "losses_to_use: ['unimodal_mse', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/39\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 34\n",
      "name: train_frames_sweep\n",
      "train_frames: 125\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/7\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 35\n",
      "name: train_frames_sweep\n",
      "train_frames: 125\n",
      "losses_to_use: ['pca_singleview', 'temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/11\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 36\n",
      "name: train_frames_sweep\n",
      "train_frames: 125\n",
      "losses_to_use: ['pca_singleview', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/15\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 37\n",
      "name: train_frames_sweep\n",
      "train_frames: 125\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse', 'temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/19\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 38\n",
      "name: train_frames_sweep\n",
      "train_frames: 125\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse', 'pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/23\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "idx: 39\n",
      "name: train_frames_sweep\n",
      "train_frames: 125\n",
      "losses_to_use: ['pca_singleview', 'unimodal_mse', 'pca_multiview', 'temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/27\n",
      "Metric: rmse\n",
      "Computing RMSE...\n"
     ]
    }
   ],
   "source": [
    "# Now for each model in a given training frame class, compute RMSE\n",
    "pca_loss = None\n",
    "data_module = None\n",
    "to_compute = 'rmse'\n",
    "metrics_collected = {bp: [] for bp in keypoint_names}\n",
    "for hand_idx, handler in enumerate(handlers):\n",
    "    print(\"idx: %i\" % hand_idx)\n",
    "    print(\"name: {}\".format(handler.cfg.model.model_name))\n",
    "    print(\"train_frames: {}\".format(handler.cfg.training.train_frames))\n",
    "    print(\"losses_to_use: {}\".format(handler.cfg.model.losses_to_use))\n",
    "    print(handler.model_dir)\n",
    "    try:\n",
    "        result = handler.compute_metric(\n",
    "            to_compute, 'predictions.csv',\n",
    "            keypoints_true=keypoints_gt, pca_loss_obj=pca_loss, datamodule=data_module)\n",
    "    except FileNotFoundError:\n",
    "        print('could not find model predictions')\n",
    "        continue\n",
    "    for b, bodypart in enumerate(keypoint_names):\n",
    "        metrics_collected[bodypart].append(result[:, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: currently ignorant of the train_frames. either fix here or above.               \n",
    "results_df = []\n",
    "for bodypart in keypoint_names:\n",
    "    dict_tmp = {\n",
    "        'bodypart': bodypart,\n",
    "        #'rng_seed': rng_seed,\n",
    "        'eval_mode': handlers[-1].pred_df.iloc[:, -1].to_numpy(),\n",
    "        'img_file': csv_data.iloc[:, 0], # TODO: fix, this is wrong. should be a str not a float\n",
    "    }\n",
    "    for col_name, metric in zip(name_strs_to_plot, metrics_collected[bodypart]):\n",
    "        dict_tmp[col_name] = metric\n",
    "    results_df.append(pd.DataFrame(dict_tmp))\n",
    "\n",
    "results_df = pd.concat(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodypart</th>\n",
       "      <th>eval_mode</th>\n",
       "      <th>img_file</th>\n",
       "      <th>tempo+unimo*50</th>\n",
       "      <th>tempo+pca_m*50</th>\n",
       "      <th>tempo+unimo+pca_m*50</th>\n",
       "      <th>unimo+pca_m*50</th>\n",
       "      <th>pca_s+unimo*50</th>\n",
       "      <th>pca_s+tempo*50</th>\n",
       "      <th>pca_s+pca_m*50</th>\n",
       "      <th>...</th>\n",
       "      <th>tempo+unimo*125</th>\n",
       "      <th>tempo+pca_m*125</th>\n",
       "      <th>tempo+unimo+pca_m*125</th>\n",
       "      <th>unimo+pca_m*125</th>\n",
       "      <th>pca_s+unimo*125</th>\n",
       "      <th>pca_s+tempo*125</th>\n",
       "      <th>pca_s+pca_m*125</th>\n",
       "      <th>pca_s+unimo+tempo*125</th>\n",
       "      <th>pca_s+unimo+pca_m*125</th>\n",
       "      <th>pca_s+unimo+pca_m+tempo*125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>unused</td>\n",
       "      <td>barObstacleScaling1/img1.png</td>\n",
       "      <td>107.167164</td>\n",
       "      <td>19.484978</td>\n",
       "      <td>49.218768</td>\n",
       "      <td>27.729192</td>\n",
       "      <td>11.284295</td>\n",
       "      <td>81.720500</td>\n",
       "      <td>40.422242</td>\n",
       "      <td>...</td>\n",
       "      <td>10.165655</td>\n",
       "      <td>13.613108</td>\n",
       "      <td>21.551051</td>\n",
       "      <td>5.469441</td>\n",
       "      <td>7.278329</td>\n",
       "      <td>39.892265</td>\n",
       "      <td>9.262841</td>\n",
       "      <td>20.134874</td>\n",
       "      <td>37.455921</td>\n",
       "      <td>7.821145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>validation</td>\n",
       "      <td>barObstacleScaling1/img2.png</td>\n",
       "      <td>32.325320</td>\n",
       "      <td>30.303992</td>\n",
       "      <td>28.153266</td>\n",
       "      <td>39.417194</td>\n",
       "      <td>21.096111</td>\n",
       "      <td>35.661139</td>\n",
       "      <td>29.156698</td>\n",
       "      <td>...</td>\n",
       "      <td>22.072084</td>\n",
       "      <td>32.700153</td>\n",
       "      <td>71.764882</td>\n",
       "      <td>79.929805</td>\n",
       "      <td>68.726678</td>\n",
       "      <td>19.663656</td>\n",
       "      <td>80.856533</td>\n",
       "      <td>69.370396</td>\n",
       "      <td>20.622683</td>\n",
       "      <td>67.822863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>test</td>\n",
       "      <td>barObstacleScaling1/img3.png</td>\n",
       "      <td>22.602413</td>\n",
       "      <td>7.744324</td>\n",
       "      <td>4.759023</td>\n",
       "      <td>66.695939</td>\n",
       "      <td>5.981631</td>\n",
       "      <td>14.399546</td>\n",
       "      <td>56.574518</td>\n",
       "      <td>...</td>\n",
       "      <td>3.976566</td>\n",
       "      <td>3.637896</td>\n",
       "      <td>5.119100</td>\n",
       "      <td>3.901515</td>\n",
       "      <td>3.260632</td>\n",
       "      <td>2.930602</td>\n",
       "      <td>2.910508</td>\n",
       "      <td>1.984852</td>\n",
       "      <td>2.912916</td>\n",
       "      <td>3.120860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>test</td>\n",
       "      <td>barObstacleScaling1/img4.png</td>\n",
       "      <td>4.198313</td>\n",
       "      <td>4.597901</td>\n",
       "      <td>1.870540</td>\n",
       "      <td>3.126915</td>\n",
       "      <td>3.041861</td>\n",
       "      <td>3.458074</td>\n",
       "      <td>3.763082</td>\n",
       "      <td>...</td>\n",
       "      <td>5.618093</td>\n",
       "      <td>2.670412</td>\n",
       "      <td>2.504021</td>\n",
       "      <td>3.312007</td>\n",
       "      <td>4.087109</td>\n",
       "      <td>4.350227</td>\n",
       "      <td>2.293038</td>\n",
       "      <td>1.783343</td>\n",
       "      <td>3.953196</td>\n",
       "      <td>1.600337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>test</td>\n",
       "      <td>barObstacleScaling1/img5.png</td>\n",
       "      <td>7.271259</td>\n",
       "      <td>7.495884</td>\n",
       "      <td>7.345606</td>\n",
       "      <td>8.308105</td>\n",
       "      <td>8.733459</td>\n",
       "      <td>9.096077</td>\n",
       "      <td>9.505998</td>\n",
       "      <td>...</td>\n",
       "      <td>10.088732</td>\n",
       "      <td>8.674619</td>\n",
       "      <td>8.053103</td>\n",
       "      <td>8.232509</td>\n",
       "      <td>8.330179</td>\n",
       "      <td>7.980887</td>\n",
       "      <td>8.358817</td>\n",
       "      <td>7.652390</td>\n",
       "      <td>8.355274</td>\n",
       "      <td>8.799086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bodypart   eval_mode                      img_file  tempo+unimo*50  \\\n",
       "0  paw1LH_top      unused  barObstacleScaling1/img1.png      107.167164   \n",
       "1  paw1LH_top  validation  barObstacleScaling1/img2.png       32.325320   \n",
       "2  paw1LH_top        test  barObstacleScaling1/img3.png       22.602413   \n",
       "3  paw1LH_top        test  barObstacleScaling1/img4.png        4.198313   \n",
       "4  paw1LH_top        test  barObstacleScaling1/img5.png        7.271259   \n",
       "\n",
       "   tempo+pca_m*50  tempo+unimo+pca_m*50  unimo+pca_m*50  pca_s+unimo*50  \\\n",
       "0       19.484978             49.218768       27.729192       11.284295   \n",
       "1       30.303992             28.153266       39.417194       21.096111   \n",
       "2        7.744324              4.759023       66.695939        5.981631   \n",
       "3        4.597901              1.870540        3.126915        3.041861   \n",
       "4        7.495884              7.345606        8.308105        8.733459   \n",
       "\n",
       "   pca_s+tempo*50  pca_s+pca_m*50  ...  tempo+unimo*125  tempo+pca_m*125  \\\n",
       "0       81.720500       40.422242  ...        10.165655        13.613108   \n",
       "1       35.661139       29.156698  ...        22.072084        32.700153   \n",
       "2       14.399546       56.574518  ...         3.976566         3.637896   \n",
       "3        3.458074        3.763082  ...         5.618093         2.670412   \n",
       "4        9.096077        9.505998  ...        10.088732         8.674619   \n",
       "\n",
       "   tempo+unimo+pca_m*125  unimo+pca_m*125  pca_s+unimo*125  pca_s+tempo*125  \\\n",
       "0              21.551051         5.469441         7.278329        39.892265   \n",
       "1              71.764882        79.929805        68.726678        19.663656   \n",
       "2               5.119100         3.901515         3.260632         2.930602   \n",
       "3               2.504021         3.312007         4.087109         4.350227   \n",
       "4               8.053103         8.232509         8.330179         7.980887   \n",
       "\n",
       "   pca_s+pca_m*125  pca_s+unimo+tempo*125  pca_s+unimo+pca_m*125  \\\n",
       "0         9.262841              20.134874              37.455921   \n",
       "1        80.856533              69.370396              20.622683   \n",
       "2         2.910508               1.984852               2.912916   \n",
       "3         2.293038               1.783343               3.953196   \n",
       "4         8.358817               7.652390               8.355274   \n",
       "\n",
       "   pca_s+unimo+pca_m+tempo*125  \n",
       "0                     7.821145  \n",
       "1                    67.822863  \n",
       "2                     3.120860  \n",
       "3                     1.600337  \n",
       "4                     8.799086  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go ahead and separate the names\n",
    "df_tmp = pd.melt(\n",
    "    results_df, \n",
    "    id_vars=['bodypart', 'img_file', 'eval_mode'],\n",
    "    value_vars=name_strs_to_plot,\n",
    ")\n",
    "def add_loss_name_col(row):\n",
    "    return '_'.join(row['variable'].split('_')[:-1])\n",
    "def add_loss_val_col(row):\n",
    "    return row['variable'].split('_')[-1]\n",
    "df_tmp['loss'] = df_tmp.apply(add_loss_name_col, axis=1) # TODO: not doing anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp[\"loss_type\"] = df_tmp.variable.str.split('*').str[0]\n",
    "df_tmp[\"train_frames\"] = df_tmp.variable.str.split('*').str[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodypart</th>\n",
       "      <th>img_file</th>\n",
       "      <th>eval_mode</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>loss</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>train_frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>barObstacleScaling1/img1.png</td>\n",
       "      <td>unused</td>\n",
       "      <td>tempo+unimo*50</td>\n",
       "      <td>107.167164</td>\n",
       "      <td></td>\n",
       "      <td>tempo+unimo</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>barObstacleScaling1/img2.png</td>\n",
       "      <td>validation</td>\n",
       "      <td>tempo+unimo*50</td>\n",
       "      <td>32.325320</td>\n",
       "      <td></td>\n",
       "      <td>tempo+unimo</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>barObstacleScaling1/img3.png</td>\n",
       "      <td>test</td>\n",
       "      <td>tempo+unimo*50</td>\n",
       "      <td>22.602413</td>\n",
       "      <td></td>\n",
       "      <td>tempo+unimo</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>barObstacleScaling1/img4.png</td>\n",
       "      <td>test</td>\n",
       "      <td>tempo+unimo*50</td>\n",
       "      <td>4.198313</td>\n",
       "      <td></td>\n",
       "      <td>tempo+unimo</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>barObstacleScaling1/img5.png</td>\n",
       "      <td>test</td>\n",
       "      <td>tempo+unimo*50</td>\n",
       "      <td>7.271259</td>\n",
       "      <td></td>\n",
       "      <td>tempo+unimo</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bodypart                      img_file   eval_mode        variable  \\\n",
       "0  paw1LH_top  barObstacleScaling1/img1.png      unused  tempo+unimo*50   \n",
       "1  paw1LH_top  barObstacleScaling1/img2.png  validation  tempo+unimo*50   \n",
       "2  paw1LH_top  barObstacleScaling1/img3.png        test  tempo+unimo*50   \n",
       "3  paw1LH_top  barObstacleScaling1/img4.png        test  tempo+unimo*50   \n",
       "4  paw1LH_top  barObstacleScaling1/img5.png        test  tempo+unimo*50   \n",
       "\n",
       "        value loss    loss_type train_frames  \n",
       "0  107.167164       tempo+unimo           50  \n",
       "1   32.325320       tempo+unimo           50  \n",
       "2   22.602413       tempo+unimo           50  \n",
       "3    4.198313       tempo+unimo           50  \n",
       "4    7.271259       tempo+unimo           50  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "train_frames\n",
       "100    16\n",
       "125    17\n",
       "50     14\n",
       "75     27\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: continue here. this will allow us to pick the best performing combo of losses for each train_frames\n",
    "df_eval = df_tmp[df_tmp.eval_mode==\"validation\"]\n",
    "df_grouped = df_eval.groupby(['loss_type', 'train_frames'])[\"value\"].mean().reset_index()\n",
    "print(df_grouped.shape)\n",
    "df_grouped.groupby(['train_frames'])[\"value\"].idxmin()\n",
    "#df_grouped.head()\n",
    "#df_grouped.groupby(['train_frames'])[\"value\"].min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context='talk', style='whitegrid', font_scale=1, rc = {'figure.figsize':(20,40)})\n",
    "eval_mode = 'test'\n",
    "saving_format = 'eps'\n",
    "y_label = \"Pixel error\"\n",
    "hue_order = None # ['s', 'unimo', 'tempo', 'pca_s', 'pca_m']\n",
    "num_losses_to_plot = 20 #len(cols_collected) # can exclude vals here\n",
    "# average over keypoints and frames\n",
    "df_tmp_ = df_tmp[df_tmp.eval_mode==eval_mode]\n",
    "g = sns.catplot(\n",
    "    data=df_tmp_, x='train_frames', hue=\"loss_type\", y='value', kind='bar', hue_order=hue_order\n",
    ")\n",
    "# for ax in g.axes:\n",
    "#     plt.setp(ax.get_yticklabels(), visible=True, rotation=None)\n",
    "#g.set_xticklabels(rotation=80, ha='center')\n",
    "# plt.title(\"train frames: {}, metric: {}, {} data\".format(train_frames, to_compute, eval_mode))\n",
    "plt.ylabel(\"{}\".format(y_label))\n",
    "plt.gcf().set_size_inches(12, 8)\n",
    "#plt.savefig('/home/jovyan/figs/{}_{}_{}_losses.{}'.format(to_compute, eval_mode, y_label, saving_format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2db7ebd2a6eaabbedad5619cf81ba50362feaaec41f65baf0d1ccad0b63e6ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

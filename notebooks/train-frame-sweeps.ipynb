{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep over `train_frames` and `losses_to_use`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "from lightning_pose.utils.io import return_absolute_data_paths\n",
    "from lightning_pose.utils.scripts import get_imgaug_transform, get_dataset, get_data_module, get_loss_factories\n",
    "from lightning_pose.losses.losses import PCALoss\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/jovyan/tracking-diagnostics')\n",
    "from diagnostics.handler import ModelHandler\n",
    "from diagnostics.io import get_base_config, get_keypoint_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% get config\n",
    "dataset_name = \"rick-configs-1\"\n",
    "base_config_dir = \"/home/jovyan/rick-configs-1\"\n",
    "base_save_dir = \"/home/jovyan/\"\n",
    "cfg = get_base_config(config_dir=base_config_dir, config_name=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load ground truth labels\n",
    "csv_file = os.path.join(cfg.data.data_dir, cfg.data.csv_file)\n",
    "csv_data = pd.read_csv(csv_file, header=list(cfg.data.header_rows))\n",
    "keypoints_gt = csv_data.iloc[:, 1:].to_numpy().reshape(csv_data.shape[0], -1, 2)\n",
    "\n",
    "keypoint_names = get_keypoint_names(csv_data, cfg.data.header_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by looping over `train_frames` and individual `losses_to_use`. Later build in complication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "searching for train_frames: 50, loss_type: []\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/1\n",
      "searching for train_frames: 50, loss_type: ['pca_multiview']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/16\n",
      "searching for train_frames: 50, loss_type: ['pca_singleview']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/0\n",
      "searching for train_frames: 50, loss_type: ['temporal']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/6\n",
      "searching for train_frames: 50, loss_type: ['unimodal_mse']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/11\n",
      "searching for train_frames: 75, loss_type: []\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/2\n",
      "searching for train_frames: 75, loss_type: ['pca_multiview']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/17\n",
      "searching for train_frames: 75, loss_type: ['pca_singleview']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/1\n",
      "searching for train_frames: 75, loss_type: ['temporal']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/7\n",
      "searching for train_frames: 75, loss_type: ['unimodal_mse']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/12\n",
      "searching for train_frames: 100, loss_type: []\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/3\n",
      "searching for train_frames: 100, loss_type: ['pca_multiview']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/18\n",
      "searching for train_frames: 100, loss_type: ['pca_singleview']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/2\n",
      "searching for train_frames: 100, loss_type: ['temporal']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/8\n",
      "searching for train_frames: 100, loss_type: ['unimodal_mse']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/13\n",
      "searching for train_frames: 125, loss_type: []\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/4\n",
      "searching for train_frames: 125, loss_type: ['pca_multiview']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/19\n",
      "searching for train_frames: 125, loss_type: ['pca_singleview']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/3\n",
      "searching for train_frames: 125, loss_type: ['temporal']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/9\n",
      "searching for train_frames: 125, loss_type: ['unimodal_mse']\n",
      "Found: train_frames_sweep\n",
      "In: /home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/14\n",
      "Found all models\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"/home/jovyan/lightning-pose\"\n",
    "loss_types = [[], [\"pca_multiview\"], [\"pca_singleview\"], [\"temporal\"], [\"unimodal_mse\"]] # TODO: order matters\n",
    "log_weight_list = [] # TODO: order matters\n",
    "model_names = [\"train_frames_sweep\"]*len(loss_types)\n",
    "supervised_model_name = model_names[0] # they all have the same name\n",
    "train_frames_list = [50,75,100,125]\n",
    "model_type = \"heatmap\"\n",
    "handlers = []\n",
    "for tr_fr_idx, train_frames in enumerate(train_frames_list):\n",
    "    for loss_idx, loss in enumerate(loss_types):\n",
    "        print(\"searching for train_frames: {}, loss_type: {}\".format(train_frames, loss))\n",
    "        model_cfg = cfg.copy()\n",
    "        model_cfg.training.train_frames = train_frames\n",
    "        model_cfg.model.losses_to_use = loss # assume loss is already a list, [] if supervised\n",
    "        model_cfg.model.model_name = model_names[loss_idx]\n",
    "        model_cfg.model.model_type = model_type\n",
    "        # specific arguments to \"train_frames_sweep\" models. TODO: change if needed\n",
    "        model_cfg.training.train_prob=0.2\n",
    "        model_cfg.training.val_prob=0.2\n",
    "        model_cfg.training.min_epochs=125\n",
    "        model_cfg.training.max_epochs=2000\n",
    "        if len(loss) == 0:\n",
    "            # support for uniquely-named supervised models\n",
    "            model_cfg.model.model_name = supervised_model_name\n",
    "        else:\n",
    "            # loop over the sub losses\n",
    "            if len(log_weight_list)>0:\n",
    "                for sub_loss_idx,sub_loss in enumerate(loss):\n",
    "                    model_cfg.losses[sub_loss].log_weight = log_weight_list[loss_idx][sub_loss_idx]\n",
    "        \n",
    "        try:\n",
    "            handlers.append(ModelHandler(save_dir, model_cfg, verbose=False))\n",
    "            print(\"Found: {}\".format(model_cfg.model.model_name))\n",
    "            print(\"In: {}\".format(handlers[-1].model_dir))\n",
    "        except FileNotFoundError:\n",
    "            print('did not find %s model for train_frames=%i' % (loss, train_frames))\n",
    "            continue\n",
    "# report on the models found\n",
    "if len(handlers) == 0:\n",
    "    print(\"No models found\")\n",
    "elif len(handlers) == len(train_frames_list)*len(loss_types):\n",
    "    print(\"Found all models\")\n",
    "else:\n",
    "    print(\"Found {} models out of {}\".format(len(handlers), len(train_frames_list)*len(loss_types)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "name: train_frames_sweep\n",
      "losses_to_use: []\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/1\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "1\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/16\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "2\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['pca_singleview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/0\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "3\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/6\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "4\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['unimodal_mse']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/11\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "5\n",
      "name: train_frames_sweep\n",
      "losses_to_use: []\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/2\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "6\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/17\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "7\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['pca_singleview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/1\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "8\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/7\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "9\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['unimodal_mse']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/12\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "10\n",
      "name: train_frames_sweep\n",
      "losses_to_use: []\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/3\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "11\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/18\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "12\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['pca_singleview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/2\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "13\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/8\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "14\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['unimodal_mse']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/13\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "15\n",
      "name: train_frames_sweep\n",
      "losses_to_use: []\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/4\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "16\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['pca_multiview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/19\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "17\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['pca_singleview']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/13-32-43/3\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "18\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['temporal']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/9\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n",
      "19\n",
      "name: train_frames_sweep\n",
      "losses_to_use: ['rmse']\n",
      "/home/jovyan/lightning-pose/multirun/2022-04-02/00-31-26/14\n",
      "Metric: rmse\n",
      "Computing RMSE...\n",
      "(1045, 17)\n"
     ]
    }
   ],
   "source": [
    "# loop over handlers and compute metrics\n",
    "to_compute = \"rmse\" # | \"rmse\" | \"pca_singleview\" | \"unimodal_mse\"\n",
    "keypoint_names = get_keypoint_names(csv_data, cfg.data.header_rows)\n",
    "model_cfg.model.losses_to_use = [loss_type] # assume loss is already a list, [] f\n",
    "error_metric = \"reprojection_error\" # only for PCA\n",
    "pca_loss = None\n",
    "data_module = None\n",
    "if to_compute == 'rmse':\n",
    "    y_label = 'RMSE per bodypart'\n",
    "elif to_compute == 'pca_multiview' or to_compute == 'pca_singleview':\n",
    "    y_label = 'PCA reprojection error'\n",
    "    from lightning_pose.utils.pca import KeypointPCA\n",
    "    data_dir, video_dir = return_absolute_data_paths(data_cfg=model_cfg.data)\n",
    "    imgaug_transform = get_imgaug_transform(cfg=model_cfg)\n",
    "    dataset = get_dataset(cfg=model_cfg, data_dir=data_dir, imgaug_transform=imgaug_transform)\n",
    "    data_module = get_data_module(cfg=model_cfg, dataset=dataset, video_dir=video_dir)\n",
    "    data_module.setup()\n",
    "    # compute pca params\n",
    "    loss_factories = get_loss_factories(cfg=model_cfg, data_module=data_module)\n",
    "    pca_loss = loss_factories[\"unsupervised\"].loss_instance_dict[to_compute]\n",
    "\n",
    "name_strs_to_plot = ['+'.join([l[:5] for l in loss]) if len(loss)>0 else 's' for loss in loss_types]\n",
    "# store results here\n",
    "if to_compute == \"pca_singleview\":\n",
    "    # remove obstacle keypoints\n",
    "    keypoint_names = [kp for kp in keypoint_names if kp not in ['obs_top','obsHigh_bot','obsLow_bot']]\n",
    "    print(keypoint_names)\n",
    "\n",
    "metrics_collected = {bp: [] for bp in keypoint_names}\n",
    "    \n",
    "for hand_idx, handler in enumerate(handlers):\n",
    "    print(hand_idx)\n",
    "    print(\"name: {}\".format(handler.cfg.model.model_name))\n",
    "    print(\"losses_to_use: {}\".format(handler.cfg.model.losses_to_use))\n",
    "    print(handler.model_dir)\n",
    "    # compute metric\n",
    "    try:\n",
    "        result = handler.compute_metric(\n",
    "            to_compute, 'predictions.csv',\n",
    "            keypoints_true=keypoints_gt, pca_loss_obj=pca_loss, datamodule=data_module)\n",
    "        print(result.shape)\n",
    "    except FileNotFoundError:\n",
    "        print('could not find model predictions')\n",
    "        continue\n",
    "    for b, bodypart in enumerate(keypoint_names):\n",
    "        metrics_collected[bodypart].append(result[:, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect results\n",
    "# TODO: currently ignorant of the train_frames. either fix here or above.               \n",
    "results_df = []\n",
    "for bodypart in keypoint_names:\n",
    "    dict_tmp = {\n",
    "        'bodypart': bodypart,\n",
    "        #'rng_seed': rng_seed,\n",
    "        'eval_mode': handlers[-1].pred_df.iloc[:, -1].to_numpy(),\n",
    "        'img_file': csv_data.iloc[:, 0], # TODO: fix, this is wrong. should be a str not a float\n",
    "    }\n",
    "    for col_name, metric in zip(name_strs_to_plot, metrics_collected[bodypart]):\n",
    "        dict_tmp[col_name] = metric\n",
    "    results_df.append(pd.DataFrame(dict_tmp))\n",
    "\n",
    "results_df = pd.concat(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bodypart</th>\n",
       "      <th>eval_mode</th>\n",
       "      <th>img_file</th>\n",
       "      <th>s</th>\n",
       "      <th>pca_m</th>\n",
       "      <th>pca_s</th>\n",
       "      <th>tempo</th>\n",
       "      <th>unimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>unused</td>\n",
       "      <td>barObstacleScaling1/img1.png</td>\n",
       "      <td>87.153238</td>\n",
       "      <td>93.340255</td>\n",
       "      <td>39.708454</td>\n",
       "      <td>106.189319</td>\n",
       "      <td>71.652569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>validation</td>\n",
       "      <td>barObstacleScaling1/img2.png</td>\n",
       "      <td>111.731015</td>\n",
       "      <td>115.790357</td>\n",
       "      <td>28.465110</td>\n",
       "      <td>60.465250</td>\n",
       "      <td>39.128012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>test</td>\n",
       "      <td>barObstacleScaling1/img3.png</td>\n",
       "      <td>81.099913</td>\n",
       "      <td>8.681526</td>\n",
       "      <td>78.112809</td>\n",
       "      <td>18.369521</td>\n",
       "      <td>74.446077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>test</td>\n",
       "      <td>barObstacleScaling1/img4.png</td>\n",
       "      <td>186.998488</td>\n",
       "      <td>2.664029</td>\n",
       "      <td>3.857219</td>\n",
       "      <td>2.859897</td>\n",
       "      <td>13.102761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paw1LH_top</td>\n",
       "      <td>test</td>\n",
       "      <td>barObstacleScaling1/img5.png</td>\n",
       "      <td>7.186884</td>\n",
       "      <td>7.548655</td>\n",
       "      <td>9.943737</td>\n",
       "      <td>6.150783</td>\n",
       "      <td>8.909237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bodypart   eval_mode                      img_file           s  \\\n",
       "0  paw1LH_top      unused  barObstacleScaling1/img1.png   87.153238   \n",
       "1  paw1LH_top  validation  barObstacleScaling1/img2.png  111.731015   \n",
       "2  paw1LH_top        test  barObstacleScaling1/img3.png   81.099913   \n",
       "3  paw1LH_top        test  barObstacleScaling1/img4.png  186.998488   \n",
       "4  paw1LH_top        test  barObstacleScaling1/img5.png    7.186884   \n",
       "\n",
       "        pca_m      pca_s       tempo      unimo  \n",
       "0   93.340255  39.708454  106.189319  71.652569  \n",
       "1  115.790357  28.465110   60.465250  39.128012  \n",
       "2    8.681526  78.112809   18.369521  74.446077  \n",
       "3    2.664029   3.857219    2.859897  13.102761  \n",
       "4    7.548655   9.943737    6.150783   8.909237  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2db7ebd2a6eaabbedad5619cf81ba50362feaaec41f65baf0d1ccad0b63e6ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

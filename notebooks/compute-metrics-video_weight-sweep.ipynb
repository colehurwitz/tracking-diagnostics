{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot train/test error across different models/n train frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from lightning_pose.utils.io import return_absolute_data_paths\n",
    "from lightning_pose.utils.scripts import get_imgaug_transform, get_dataset, get_data_module\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/mattw/Dropbox/github/paninski-lab/tracking-diagnostics')\n",
    "from diagnostics.handler import ModelHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"ibl-fingers\"\n",
    "# dataset_name = \"ibl-pupil-2\"\n",
    "# dataset_name = \"ibl-paw-2\"\n",
    "base_config_dir = \"/home/mattw/Dropbox/research-code/pose-estimation/configs\"\n",
    "base_save_dir = \"/media/mattw/behavior/results/pose-estimation/\"\n",
    "\n",
    "hydra.initialize_config_dir(base_config_dir)\n",
    "cfg = hydra.compose(config_name=\"config_%s\" % dataset_name)\n",
    "cfg.training.imgaug = \"default\"\n",
    "\n",
    "# load ground truth labels\n",
    "csv_file = os.path.join(cfg.data.data_dir, cfg.data.csv_file)\n",
    "csv_data = pd.read_csv(csv_file, header=list(cfg.data.header_rows))\n",
    "keypoints_gt = csv_data.iloc[:, 1:].to_numpy().reshape(csv_data.shape[0], -1, 2)\n",
    "if len(cfg.data.header_rows) == 3:\n",
    "    keypoint_names = [c[1] for c in csv_data.columns[1::2]]\n",
    "else:\n",
    "    keypoint_names = [c[0] for c in csv_data.columns[1::2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data module\n",
    "data_dir, video_dir = return_absolute_data_paths(data_cfg=cfg.data)\n",
    "imgaug_transform = get_imgaug_transform(cfg=cfg)\n",
    "dataset = get_dataset(cfg=cfg, data_dir=data_dir, imgaug_transform=imgaug_transform)\n",
    "data_module = get_data_module(cfg=cfg, dataset=dataset, video_dir=video_dir)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dir = os.path.join(base_save_dir, dataset_name)\n",
    "\n",
    "# define models\n",
    "to_compute = 'pca_reproj'  # pca_reproj | unimodal_mse | temporal_norm\n",
    "model_name = 'grid-search-0'\n",
    "train_frame = 1 # 000\n",
    "rng_seed = 0\n",
    "\n",
    "loss_weight_dict = {\n",
    "    'supervised': [None],\n",
    "#     'unimodal_mse': [10.0, 1.0],\n",
    "    'temporal': [4.0, 3.0, 2.0, 1.0, 0.0, -1.0, -2.0, -3.0, -4.0],\n",
    "    'pca_singleview': [4.0, 3.0, 2.0, 1.0, 0.0, -1.0, -2.0, -3.0, -4.0],\n",
    "}\n",
    "\n",
    "pca_obj = None\n",
    "datamodule = None\n",
    "\n",
    "if to_compute == 'rmse':\n",
    "    raise NotImplementedError\n",
    "elif to_compute == 'pca_reproj':\n",
    "    y_label = 'PCA reprojection error'\n",
    "    from lightning_pose.utils.pca import KeypointPCA\n",
    "    pca_obj = KeypointPCA(loss_type='pca_singleview', data_module=data_module)\n",
    "    pca_obj()\n",
    "elif to_compute == 'unimodal_mse':\n",
    "    y_label = 'Unimodal MSE'\n",
    "elif to_compute == 'temporal_norm':\n",
    "    y_label = 'Temporal norm'\n",
    "\n",
    "if dataset_name == \"ibl-paw-2\":\n",
    "    test_videos_directory = os.path.join(data_dir, 'videos_og_short')\n",
    "elif dataset_name == \"ibl-pupil-2\":\n",
    "    test_videos_directory = os.path.join(data_dir, 'videos_test')\n",
    "elif dataset_name == \"ibl-fingers\":\n",
    "    test_videos_directory = os.path.join(data_dir, 'videos')\n",
    "\n",
    "video_names = os.listdir(test_videos_directory)\n",
    "video_names.sort()\n",
    "\n",
    "results_df = []\n",
    "n_vids = 0\n",
    "for video_name in video_names: #[::2][:10]:\n",
    "    n_vids += 1\n",
    "    \n",
    "    # store results here\n",
    "    metrics_collected = {bp: [] for bp in keypoint_names}\n",
    "    cols_collected = []\n",
    "    video_file = os.path.join(test_videos_directory, video_name)\n",
    "    # loop over models and compute metric of interest\n",
    "    for loss_type, loss_weights in loss_weight_dict.items():\n",
    "        for loss_weight in loss_weights:\n",
    "\n",
    "            # find model checkpoint\n",
    "            model_cfg = cfg.copy()\n",
    "            model_cfg.training.train_frames = train_frame\n",
    "            model_cfg.training.rng_seed_data_pt = rng_seed\n",
    "            model_cfg.training.rng_seed_data_dali = rng_seed\n",
    "            model_cfg.training.rng_seed_model_pt = rng_seed\n",
    "            model_cfg.model.model_name = model_name\n",
    "\n",
    "            # put model-specific config info here\n",
    "            if loss_type == 'supervised':\n",
    "                model_cfg.model.losses_to_use = []    \n",
    "            else:\n",
    "                model_cfg.model.losses_to_use = [loss_type]\n",
    "                model_cfg.losses[loss_type].log_weight = loss_weight\n",
    "    #                 print(model_cfg.losses)\n",
    "\n",
    "            try:\n",
    "                handler = ModelHandler(save_dir, model_cfg, verbose=False)\n",
    "            except FileNotFoundError:\n",
    "                print('did not find %s model for train_frames=%i' % (loss_type, train_frame))\n",
    "                continue\n",
    "\n",
    "            filename_pred = video_name.replace('.mp4', '_predictions.csv')\n",
    "            saved_vid_preds_dir = os.path.join(handler.model_dir, 'video_predictions')\n",
    "            pred_csv_file = os.path.join(saved_vid_preds_dir, filename_pred)\n",
    "            print(pred_csv_file)\n",
    "            filename_heat = video_name.replace('.mp4', '_heatmaps.h5')\n",
    "            saved_heat_dir = os.path.join(handler.model_dir, 'video_heatmaps')\n",
    "            heat_h5_file = os.path.join(saved_heat_dir, filename_heat)\n",
    "            try:\n",
    "                result = handler.compute_metric(\n",
    "                    to_compute, pred_csv_file,\n",
    "                    pca_obj=pca_obj, datamodule=datamodule, heatmap_file=heat_h5_file)\n",
    "            except FileNotFoundError:\n",
    "                print('could not find model predictions')\n",
    "                continue\n",
    "\n",
    "            if loss_type == 'supervised':\n",
    "                for loss_type_, loss_weights_ in loss_weight_dict.items():\n",
    "                    if loss_type_ == 'supervised':\n",
    "                        # make a supervised entry, but not under this name\n",
    "                        continue\n",
    "                    else:\n",
    "                        cols_collected.append('%s_s' % loss_type_)\n",
    "                        for b, bodypart in enumerate(keypoint_names):\n",
    "                            metrics_collected[bodypart].append(result[:, b])\n",
    "            else:\n",
    "                cols_collected.append('%s_%.1f' % (loss_type, loss_weight))\n",
    "                for b, bodypart in enumerate(keypoint_names):\n",
    "                    metrics_collected[bodypart].append(result[:, b])\n",
    "\n",
    "    # collect results\n",
    "    for bodypart in keypoint_names:\n",
    "        dict_tmp = {\n",
    "            'bodypart': bodypart,\n",
    "            'video': video_name.split('_')[0].split('-')[0],\n",
    "        }\n",
    "        for col_name, metric in zip(cols_collected, metrics_collected[bodypart]):\n",
    "            dict_tmp[col_name] = metric\n",
    "        dict_tmp['time_idx'] = np.arange(result.shape[0])\n",
    "        results_df.append(pd.DataFrame(dict_tmp))\n",
    "\n",
    "results_df = pd.concat(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scatterplots for a pair of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "results_tmp = results_df.copy()\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "fig = px.scatter(\n",
    "    results_tmp, \n",
    "    # x='unimodal_mse_0', y='unimodal_mse_1.0',\n",
    "    #x='temporal_s', y='temporal_0.0',\n",
    "    x='temporal_s', y='pca_singleview_-4.0',\n",
    "    facet_col='bodypart',\n",
    "#     facet_col_wrap=2,\n",
    "    facet_row='video',\n",
    "    hover_data=['time_idx'],\n",
    "    log_x=True,\n",
    "    log_y=True,\n",
    "    opacity=0.5,\n",
    "    title='PCA reprojection error (%s)' % dataset_name,\n",
    "#     trendline=\"ols\",\n",
    "#     marginal_x='histogram',\n",
    "#     marginal_y='histogram',\n",
    ")\n",
    "fig.update_traces(marker={'size': 5})\n",
    "\n",
    "# trace = go.Scatter(x=[0.1, 10], y=[0.1, 10], line_color=\"black\", mode=\"lines\")\n",
    "# trace.update(legendgroup=\"trendline\", showlegend=False)\n",
    "# fig.add_trace(trace, row=\"all\", col=\"all\", exclude_empty_subplots=True)\n",
    "fig.update_layout(width=800, height=300)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### barplots across all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.melt(\n",
    "    results_df, \n",
    "    id_vars=['bodypart', 'time_idx', 'video'], \n",
    "    value_vars=cols_collected\n",
    ")\n",
    "def add_loss_name_col(row):\n",
    "    return '_'.join(row['variable'].split('_')[:-1])\n",
    "def add_loss_val_col(row):\n",
    "    return row['variable'].split('_')[-1]\n",
    "df_tmp['loss'] = df_tmp.apply(add_loss_name_col, axis=1)\n",
    "df_tmp['loss_weight'] = df_tmp.apply(add_loss_val_col, axis=1)\n",
    "df_tmp = df_tmp.drop('variable', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context='talk', style='whitegrid', font_scale=1)\n",
    "\n",
    "df_tmp_ = df_tmp.groupby(['bodypart', 'video', 'loss', 'loss_weight']).mean().reset_index()\n",
    "\n",
    "g = sns.catplot(\n",
    "    x='loss_weight', y='value', \n",
    "    log=True,\n",
    "    order=['s'] + [str(w) for w in loss_weight_dict['pca_singleview']],\n",
    "#     kind='strip', dodge=True,\n",
    "    kind='bar',\n",
    "    \n",
    "#     col='loss',\n",
    "#     col_wrap=np.min([len(df_tmp_.loss.unique()), 3]), \n",
    "#     data=df_tmp_,\n",
    "#     col_order=['temporal', 'pca_singleview'],\n",
    "    \n",
    "    col='bodypart',\n",
    "    sharey=False,\n",
    "    data=df_tmp_[df_tmp_.loss=='pca_singleview'],\n",
    ")\n",
    "g.set_axis_labels('Loss weight', y_label)\n",
    "g.set_xticklabels(rotation=45, ha='center')\n",
    "\n",
    "for ax in g.axes.flatten():\n",
    "    ax.tick_params(axis='y', which='both', direction='out', length=4, left=True)\n",
    "    ax.grid(b=True, which='both', color='gray', linewidth=0.1)\n",
    "\n",
    "if dataset_name == 'ibl-paw-2':\n",
    "    if to_compute == 'temporal_norm':\n",
    "        g.set(ylim=[0.1, 1])\n",
    "#         if eval_mode == 'unused':\n",
    "#             g.set(ylim=[3.8, 4.8])\n",
    "#         elif eval_mode == 'validation':\n",
    "#             g.set(ylim=[4, 5.7])\n",
    "#         elif eval_mode == 'train':\n",
    "#             g.set(ylim=[4, 5.5])\n",
    "elif dataset_name == 'ibl-pupil-2':\n",
    "    if to_compute == 'unimodal_mse':\n",
    "        g.set(ylim=[1e-3, 1e-2])\n",
    "    elif to_compute == 'pca_reproj':\n",
    "        g.set(ylim=[0.08, 6])\n",
    "    elif to_compute == 'temporal_norm':\n",
    "        g.set(ylim=[0.05, 3])\n",
    "\n",
    "# g.set(ylim=[12, 14.4])\n",
    "\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('%s (averaged across %i videos)' % (y_label, n_vids))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose",
   "language": "python",
   "name": "pose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

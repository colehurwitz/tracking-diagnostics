{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot train/test error across different models/n train frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "from lightning_pose.utils.io import return_absolute_data_paths\n",
    "from lightning_pose.utils.scripts import (\n",
    "    get_imgaug_transform, get_dataset, get_data_module, get_loss_factories,\n",
    ")\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/mattw/Dropbox/github/paninski-lab/tracking-diagnostics')\n",
    "from diagnostics.handler import ModelHandler\n",
    "from diagnostics.io import get_keypoint_names, get_base_config, update_loss_config\n",
    "from diagnostics.visualizations import get_y_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = \"ibl-fingers\"\n",
    "# dataset_name = \"ibl-pupil-2\"\n",
    "# dataset_name = \"ibl-pupil-ks004\"\n",
    "# dataset_name = \"ibl-paw-2\"\n",
    "# dataset_name = 'mirror-mouse-1.5'\n",
    "# dataset_name = 'mirror-fish'\n",
    "dataset_name = \"fly\"\n",
    "\n",
    "base_config_dir = \"/home/mattw/Dropbox/research-code/pose-estimation/configs\"\n",
    "base_save_dir = \"/media/mattw/behavior/results/pose-estimation/\"\n",
    "\n",
    "model_name = 'hparam-search_07-22b' #'grid-search-0'\n",
    "\n",
    "cfg = get_base_config(base_config_dir, \"config_%s\" % dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ground truth labels\n",
    "csv_file = os.path.join(cfg.data.data_dir, cfg.data.csv_file)\n",
    "csv_data = pd.read_csv(csv_file, header=list(cfg.data.header_rows))\n",
    "keypoints_gt = csv_data.iloc[:, 1:].to_numpy().reshape(csv_data.shape[0], -1, 2)\n",
    "keypoint_names = get_keypoint_names(csv_data, cfg.data.header_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data module\n",
    "data_dir, video_dir = return_absolute_data_paths(data_cfg=cfg.data)\n",
    "imgaug_transform = get_imgaug_transform(cfg=cfg)\n",
    "dataset = get_dataset(cfg=cfg, data_dir=data_dir, imgaug_transform=imgaug_transform)\n",
    "data_module = get_data_module(cfg=cfg, dataset=dataset, video_dir=video_dir)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dir = os.path.join(base_save_dir, dataset_name)\n",
    "\n",
    "# define models\n",
    "to_compute = \"temporal_norm\"  # pca_multiview | pca_singleview | unimodal_mse | temporal_norm\n",
    "train_frame = 75\n",
    "rng_seeds = [0] #, 1, 2]\n",
    "model_type = \"heatmap\"\n",
    "do_context = False\n",
    "\n",
    "loss_weight_dict = {\n",
    "    'supervised': [None],\n",
    "#     'temporal': [4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 8.0],\n",
    "    'pca_singleview': [4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 8.0],\n",
    "#     'pca_singleview': [3.0, 4.0, 4.5, 5.0, 5.5, 6.0],\n",
    "#     'pca_multiview': [4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0],\n",
    "}\n",
    "\n",
    "pca_obj = None\n",
    "pca_loss = None\n",
    "datamodule = None\n",
    "\n",
    "test_videos_directory = os.path.join(data_dir, 'videos_test')\n",
    "video_names = os.listdir(test_videos_directory)\n",
    "video_names.sort()\n",
    "\n",
    "results_df = []\n",
    "n_vids = 0\n",
    "for video_name in video_names: #[::2][:10]:\n",
    "    if not video_name.endswith('.mp4'):\n",
    "        continue\n",
    "    n_vids += 1\n",
    "    \n",
    "    for rng_seed in rng_seeds:\n",
    "        # store results here\n",
    "        metrics_collected = {bp: [] for bp in keypoint_names}\n",
    "        cols_collected = []\n",
    "        video_file = os.path.join(test_videos_directory, video_name)\n",
    "        # loop over models and compute metric of interest\n",
    "        for loss_type, loss_weights in loss_weight_dict.items():\n",
    "            for loss_weight in loss_weights:\n",
    "\n",
    "                # model_name = 'hparam-search_07-22c' if loss_type == \"supervised\" else 'hparam-search_07-22c_control'\n",
    "                \n",
    "                # find model checkpoint\n",
    "                model_cfg = cfg.copy()\n",
    "                model_cfg.model.do_context = do_context\n",
    "                model_cfg.training.train_frames = train_frame\n",
    "                model_cfg.training.rng_seed_data_pt = rng_seed\n",
    "                model_cfg.training.rng_seed_model_pt = 0  #rng_seed\n",
    "                model_cfg.model.model_name = model_name\n",
    "\n",
    "                # put model-specific config info here\n",
    "                if loss_type == 'supervised':\n",
    "                    model_cfg.model.losses_to_use = []    \n",
    "                else:\n",
    "                    model_cfg = update_loss_config(model_cfg, loss_type, loss_weight)\n",
    "\n",
    "                try:\n",
    "                    handler = ModelHandler(\n",
    "                        save_dir, model_cfg, verbose=False,\n",
    "                        keys_to_sweep=['limit_train_batches'])\n",
    "                except FileNotFoundError:\n",
    "                    print('did not find %s model for train_frames=%i' % (loss_type, train_frame))\n",
    "                    continue\n",
    "\n",
    "                filename_pred = video_name.replace('.mp4', '.csv')\n",
    "                saved_vid_preds_dir = os.path.join(handler.model_dir, 'video_preds')\n",
    "                pred_csv_file = os.path.join(saved_vid_preds_dir, filename_pred)\n",
    "                try:\n",
    "                    result, _ = handler.compute_metric(\n",
    "                        to_compute, pred_csv_file,\n",
    "                        video_file=video_file,\n",
    "                        confidence_thresh=0.05,\n",
    "                        pca_loss_obj=pca_loss, # datamodule=datamodule,\n",
    "                    )\n",
    "                except FileNotFoundError:\n",
    "                    print('could not find model predictions')\n",
    "                    continue\n",
    "\n",
    "                if loss_type == 'supervised':\n",
    "                    for loss_type_, loss_weights_ in loss_weight_dict.items():\n",
    "                        if loss_type_ == 'supervised':\n",
    "                            # make a supervised entry, but not under this name\n",
    "                            continue\n",
    "                        else:\n",
    "                            cols_collected.append('%s_s' % loss_type_)\n",
    "                            for b, bodypart in enumerate(keypoint_names):\n",
    "                                metrics_collected[bodypart].append(result[:, b])\n",
    "    #                             metrics_collected[bodypart].append(np.log(result[:, b]))\n",
    "                else:\n",
    "                    cols_collected.append('%s_%.1f' % (loss_type, loss_weight))\n",
    "                    for b, bodypart in enumerate(keypoint_names):\n",
    "                        metrics_collected[bodypart].append(result[:, b])\n",
    "    #                     metrics_collected[bodypart].append(np.log(result[:, b]))\n",
    "\n",
    "        # collect results\n",
    "        for bodypart in keypoint_names:\n",
    "            dict_tmp = {\n",
    "                'bodypart': bodypart,\n",
    "                'rng_seed': rng_seed,\n",
    "                # 'video': video_name.split('_')[0].split('-')[0],\n",
    "                'video': video_name[:10], #[0].split('-')[0],\n",
    "            }\n",
    "    #         for col_name, metric in zip(cols_collected, metrics_collected[bodypart]):\n",
    "    #             dict_tmp[col_name] = np.sum(metric > eps)\n",
    "    #         results_df.append(pd.DataFrame(dict_tmp, index=[0]))\n",
    "            for col_name, metric in zip(cols_collected, metrics_collected[bodypart]):\n",
    "                dict_tmp[col_name] = metric\n",
    "            # dict_tmp['time_idx'] = ['%s_%i' % (video_name, n) for n in np.arange(metric.shape[0])]\n",
    "            results_df.append(pd.DataFrame(dict_tmp))\n",
    "\n",
    "results_df = pd.concat(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scatterplots for a pair of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_context('talk')\n",
    "# sns.set_style('whitegrid')\n",
    "\n",
    "# results_tmp = results_df.copy()\n",
    "\n",
    "# x = 'pca_multiview_s'\n",
    "# # y = 'multi_temp_7.0'\n",
    "# y = 'pca_multiview_7.0'\n",
    "\n",
    "# eps = 5\n",
    "# # results_tmp.loc[(results_tmp[x] < eps) & (results_tmp[y] < eps), x] = np.nan\n",
    "# # results_tmp.loc[(results_tmp[x] < eps) & (results_tmp[y] < eps), y] = np.nan\n",
    "\n",
    "# import plotly.express as px\n",
    "# import plotly.graph_objects as go\n",
    "# fig = px.scatter(\n",
    "#     results_tmp, \n",
    "#     x=x, y=y,\n",
    "    \n",
    "# #     facet_col='bodypart',\n",
    "# #     facet_row='video',\n",
    "\n",
    "# #     color='video',  \n",
    "#     facet_col='bodypart',\n",
    "#     facet_col_wrap=4,\n",
    "    \n",
    "#     # hover_data=['time_idx'],\n",
    "#     log_x=True,\n",
    "#     log_y=True,\n",
    "#     opacity=0.25,\n",
    "#     title='Temporal norm (%s)' % dataset_name,\n",
    "#     range_x=[eps - 1, 100],\n",
    "#     range_y=[eps - 1, 100],\n",
    "# #     trendline=\"ols\",\n",
    "# #     marginal_x='histogram',\n",
    "# #     marginal_y='histogram',\n",
    "# )\n",
    "# fig.update_traces(marker={'size': 3})\n",
    "\n",
    "# trace = go.Scatter(x=[eps, 100], y=[eps, 100], line_color=\"black\", mode=\"lines\")\n",
    "# trace.update(legendgroup=\"trendline\", showlegend=False)\n",
    "# fig.add_trace(trace, row=\"all\", col=\"all\", exclude_empty_subplots=True)\n",
    "# fig.update_layout(width=800, height=1200)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### barplots across all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars = ['bodypart', 'video', 'rng_seed']\n",
    "if 'time_idx' in results_df.keys():\n",
    "    id_vars += ['time_idx']\n",
    "df_tmp = pd.melt(\n",
    "    results_df, \n",
    "    id_vars=id_vars, \n",
    "    value_vars=cols_collected\n",
    ")\n",
    "def add_loss_name_col(row):\n",
    "    return '_'.join(row['variable'].split('_')[:-1])\n",
    "def add_loss_val_col(row):\n",
    "    return row['variable'].split('_')[-1]\n",
    "df_tmp['loss'] = df_tmp.apply(add_loss_name_col, axis=1)\n",
    "df_tmp['loss_weight'] = df_tmp.apply(add_loss_val_col, axis=1)\n",
    "df_tmp = df_tmp.drop('variable', axis=1)\n",
    "\n",
    "eps = 5\n",
    "df_tmp = df_tmp[df_tmp.value > eps]\n",
    "\n",
    "# take mean over keypoints, so that error bars are over rng seeds\n",
    "df_tmp = df_tmp.groupby(['rng_seed', 'loss', 'loss_weight', 'video']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context='talk', style='whitegrid', font_scale=1)\n",
    "\n",
    "y_label = get_y_label(to_compute)\n",
    "\n",
    "# df_tmp_ = df_tmp.groupby(['bodypart', 'video', 'loss', 'loss_weight']).mean().reset_index()\n",
    "# df_tmp_ = df_tmp.copy()\n",
    "df_tmp_ = df_tmp #[df_tmp.value > eps]\n",
    "\n",
    "count_plot = False\n",
    "\n",
    "if count_plot:\n",
    "    kind = 'count'\n",
    "    y = None\n",
    "    y_label_ = 'Number of violations'\n",
    "else:\n",
    "    kind = 'bar'\n",
    "    y = 'value'\n",
    "    y_label_ = y_label\n",
    "    \n",
    "g = sns.catplot(\n",
    "    x='loss_weight', y=y, \n",
    "#     log=True,\n",
    "#     order=['s'] + [str(w) for w in loss_weight_dict['pca_multiview']],\n",
    "    kind=kind,\n",
    "    \n",
    "#     col='loss',\n",
    "#     col_wrap=np.min([len(df_tmp_.loss.unique()), 3]), \n",
    "#     data=df_tmp_,\n",
    "#     col_order=['temporal', 'pca_singleview'],\n",
    "    \n",
    "#     col='bodypart',\n",
    "#     row='loss',\n",
    "#     col='bodypart',\n",
    "#     col_wrap=4,\n",
    "    sharey=False,\n",
    "    ci=95,\n",
    "    data=df_tmp_, #[df_tmp_.loss=='pca_singleview'],\n",
    ")\n",
    "# g = sns.displot(\n",
    "#     hue='loss_weight', x='value', \n",
    "# #     kind='strip', dodge=True,\n",
    "#     col='bodypart',\n",
    "#     col_wrap=4,\n",
    "# #     sharey=False,\n",
    "#     data=df_tmp, #[df_tmp_.loss=='pca_singleview'],\n",
    "# )\n",
    "\n",
    "g.set_axis_labels('Loss weight', y_label_)\n",
    "g.set_xticklabels(rotation=45, ha='center')\n",
    "\n",
    "for ax in g.axes.flatten():\n",
    "    ax.tick_params(axis='y', which='both', direction='out', length=4, left=True)\n",
    "    ax.grid(b=True, which='both', color='gray', linewidth=0.1)\n",
    "\n",
    "# g.set(ylim=[0.01, 40])\n",
    "\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('%s violations (%i videos)' % (y_label, n_vids))\n",
    "plt.tight_layout()\n",
    "base_dir = '/home/mattw/Dropbox/research-text/posters/2022_naisys_litpose'\n",
    "# plt.savefig(os.path.join(base_dir, 'rick-mouse_held-out_rmse_eps=5.pdf'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### by bodypart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(context='talk', style='whitegrid', font_scale=1)\n",
    "\n",
    "# df_tmp_ = df_tmp.groupby(['bodypart', 'video', 'loss', 'loss_weight']).mean().reset_index()\n",
    "# df_tmp_ = df_tmp.copy()\n",
    "\n",
    "df_tmp_ = df_tmp[df_tmp.value > eps]\n",
    "\n",
    "count_plot = False\n",
    "\n",
    "if count_plot:\n",
    "    kind = 'count'\n",
    "    y = None\n",
    "    y_label_ = 'Number of violations'\n",
    "else:\n",
    "    kind = 'boxen'\n",
    "    y = 'value'\n",
    "    y_label_ = y_label\n",
    "    \n",
    "g = sns.catplot(\n",
    "    x='loss_weight', y=y, \n",
    "#     log=True,\n",
    "    order=['s'] + [str(w) for w in loss_weight_dict['pca_multiview']],\n",
    "    kind=kind,\n",
    "    \n",
    "#     col='loss',\n",
    "#     col_wrap=np.min([len(df_tmp_.loss.unique()), 3]), \n",
    "#     data=df_tmp_,\n",
    "#     col_order=['temporal', 'pca_singleview'],\n",
    "    \n",
    "#     col='bodypart',\n",
    "#     row='loss',\n",
    "    col='bodypart',\n",
    "    col_wrap=4,\n",
    "    sharey=False,\n",
    "    ci=95,\n",
    "    data=df_tmp_, #[df_tmp_.loss=='pca_singleview'],\n",
    ")\n",
    "# g = sns.displot(\n",
    "#     hue='loss_weight', x='value', \n",
    "# #     kind='strip', dodge=True,\n",
    "#     col='bodypart',\n",
    "#     col_wrap=4,\n",
    "# #     sharey=False,\n",
    "#     data=df_tmp, #[df_tmp_.loss=='pca_singleview'],\n",
    "# )\n",
    "\n",
    "g.set_axis_labels('Loss weight', y_label_)\n",
    "g.set_xticklabels(rotation=45, ha='center')\n",
    "\n",
    "for ax in g.axes.flatten():\n",
    "    ax.tick_params(axis='y', which='both', direction='out', length=4, left=True)\n",
    "    ax.grid(b=True, which='both', color='gray', linewidth=0.1)\n",
    "\n",
    "# g.set(ylim=[0.01, 40])\n",
    "\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('%s violations (%i videos)' % (y_label, n_vids))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose",
   "language": "python",
   "name": "pose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
